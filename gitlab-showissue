#!/usr/bin/env python3

# Copyright Â© 2022 Jakub Wilk <jwilk@jwilk.net>
# SPDX-License-Identifier: MIT

import argparse
import html.parser
import io
import json
import re
import signal
import urllib.parse
import urllib.request

lambda x, /: 0  # Python >= 3.8 is required

user_agent = 'gitlab-toolbox (https://github.com/jwilk/gitlab-toolbox)'

class HTTPRedirectHandler(urllib.request.HTTPRedirectHandler):

    def redirect_request(self, req, fp, code, msg, headers, newurl):
        sign_in_url = '/users/sign_in'
        if newurl.endswith(sign_in_url):
            raise RuntimeError(f'{req.full_url} redirects to ...{sign_in_url}')
        return super().redirect_request(req, fp, code, msg, headers, newurl)

http_opener = urllib.request.build_opener(HTTPRedirectHandler)

def wget(url):
    headers = {'User-Agent': user_agent}
    request = urllib.request.Request(url, headers=headers)
    return http_opener.open(request)

def wget_json(url):
    with wget(url) as fp:
        with io.TextIOWrapper(fp, encoding='UTF-8') as tfp:
            return json.load(tfp, object_hook=DictProxy)

class DictProxy(object):

    def __init__(self, d):
        self._d = d

    def __getattr__(self, attr):
        return self._d[attr]

def fmt_date(d):
    d = re.sub(r'[.]\d+', '', d)
    d = d.replace('T', ' ')
    return d

def fmt_user(user, url):
    url = urllib.request.urljoin(url, user.path)
    return f'{user.name} <{url}>'

def xmain():
    ap = argparse.ArgumentParser()
    ap.add_argument('url', metavar='URL')
    opts = ap.parse_args()
    opts.url, _ = urllib.parse.urldefrag(opts.url)
    author = None
    class HTMLParser(html.parser.HTMLParser):
        def handle_starttag(self, tag, attrs):
            nonlocal author
            if tag == 'a':
                attrs = dict(attrs)
                classes = attrs.get('class', '').split()
                if 'author-link' in classes:
                    userurl = urllib.request.urljoin(opts.url, attrs['href'])
                    username = attrs['data-name']
                    author = f'{username} <{userurl}>'
    html_parser = HTMLParser()
    with wget(opts.url) as fp:
        with io.TextIOWrapper(fp, encoding='UTF-8') as tfp:
            data = tfp.read()
        html_parser.feed(data)
    jurl = f'{opts.url}.json'
    data = wget_json(jurl)
    print('Location:', urllib.parse.urljoin(opts.url, data.web_url))
    if author:
        print('From:', author)
    print('Title:', data.title)
    try:
        data_type = data.type
    except KeyError:
        pass
    else:
        print('Type:', data_type)
    print('Date:', fmt_date(data.created_at))
    if data.updated_at != data.created_at:
        print('Update:', fmt_date(data.updated_at))
    if labels := [label.title for label in data.labels]:
        print('Labels:', *labels)
    print()
    print(data.description)
    jurl = f'{opts.url}/discussions.json'
    data = wget_json(jurl)
    for item in data:
        for note in item.notes:
            print()
            print('-' * 72)
            if url := note.noteable_note_url:
                print('Location:', url)
            print('From:', fmt_user(note.author, url or jurl))
            print('Date:', fmt_date(note.created_at))
            if (note.updated_at is not None) and (note.updated_at != note.created_at):
                print('Update:', fmt_date(note.updated_at))
            print()
            print(note.note)

def main():
    try:
        xmain()
    except BrokenPipeError:
        signal.signal(signal.SIGPIPE, signal.SIG_DFL)
        signal.raise_signal(signal.SIGPIPE)
        raise

if __name__ == '__main__':
    main()

# vim:ts=4 sts=4 sw=4 et
